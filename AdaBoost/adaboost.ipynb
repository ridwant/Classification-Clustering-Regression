{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# import libraries\n",
        "\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.metrics import f1_score, accuracy_score, classification_report, confusion_matrix, precision_score, recall_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import random\n",
        "\n",
        "from google.colab import files\n",
        "from scipy import sparse\n",
        "\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold, StratifiedKFold\n",
        "\n",
        "from sklearn.feature_selection import SelectKBest, f_regression, chi2\n",
        "from numpy import mean\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "l2aXjIJArGIj"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_data_url = 'https://raw.githubusercontent.com/ridwant/DataMinig/main/hw2train.txt'\n",
        "test_data_url = 'https://raw.githubusercontent.com/ridwant/DataMinig/main/1664296410_921989_test.txt'\n",
        "\n",
        "train_df = pd.read_table(train_data_url, header=None, skip_blank_lines=False, names=['active', 'attribute'])\n",
        "test_df = pd.read_table(test_data_url, header=None, skip_blank_lines=False, names=['attribute'])\n",
        "train_df['active'] = train_df['active'].map({1: 1, 0: -1})"
      ],
      "metadata": {
        "id": "EmyC4fsLxYzQ"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_sparse_matrix(samples):\n",
        "  vals = []\n",
        "  row_idxs = []\n",
        "  col_idxs = []\n",
        "  for idx, sample in enumerate(samples):\n",
        "    sample = sample.strip().split(\" \")\n",
        "    for s in sample:\n",
        "      if s.strip() != '':\n",
        "        col_idxs.append(int(s))\n",
        "        row_idxs.append(idx)\n",
        "        vals.append(1)\n",
        "  csc = sparse.csc_matrix((vals, (row_idxs, col_idxs)))\n",
        "\n",
        "  return csc"
      ],
      "metadata": {
        "id": "cQXUDaf0Ofl7"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AdaBoostClassifier:\n",
        "\n",
        "  def __init__(self, n_estimators=20):\n",
        "    self.alpha = []\n",
        "    self.weak_estimator = []\n",
        "    self.n_estimators = n_estimators\n",
        "    self.errors = []\n",
        "\n",
        "  def misclassification_rate(self, misclassified_labels, weights):\n",
        "    # misclassification rate / sum of the weights \n",
        "    return (sum(weights * misclassified_labels))/sum(weights)\n",
        "\n",
        "  def get_alpha(self, err):\n",
        "    return np.log((1 - err) / err)\n",
        "\n",
        "  def update_weights(self, misclassified_labels, weights, alpha):\n",
        "    return weights * np.exp(alpha * misclassified_labels)\n",
        "  \n",
        "  def fit(self, X, y, alter_base=False):\n",
        "    weights_i = (np.ones(X.shape[0]) * 1) / X.shape[0]\n",
        "    for i in range(self.n_estimators):\n",
        "      if not alter_base:\n",
        "        estimator = DecisionTreeClassifier(max_depth=1, random_state=123)\n",
        "      else:\n",
        "        estimator = BernoulliNB()\n",
        "      estimator.fit(X,y, sample_weight=weights_i)\n",
        "      self.weak_estimator.append(estimator)\n",
        "      y_pred = estimator.predict(X)\n",
        "      y_true = y.values\n",
        "      misclassified_labels = np.not_equal(y_true, y_pred).astype(int)\n",
        "      error_i = self.misclassification_rate(misclassified_labels, weights_i)\n",
        "      self.errors.append(error_i)\n",
        "      alpha_i = self.get_alpha(error_i)\n",
        "      self.alpha.append(alpha_i)\n",
        "      weights_i = self.update_weights(misclassified_labels, weights_i, alpha_i)\n",
        "  \n",
        "\n",
        "  def predict(self, X):\n",
        "    y_pred_i = [self.alpha[idx] * estimator.predict(X) for idx, estimator in enumerate(self.weak_estimator)]\n",
        "    y_pred = np.sum(y_pred_i,axis=0)\n",
        "    y_pred = np.sign(y_pred)\n",
        "    return y_pred"
      ],
      "metadata": {
        "id": "zSsf1i_O8dGN"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def stratified_kFold_cross_validation_with_adaboost(X, Y, fold=5, n_estimators=20, alter_base = False):\n",
        "  ab = AdaBoostClassifier(n_estimators=n_estimators)\n",
        "  skf = StratifiedKFold(n_splits=fold, shuffle=True, random_state=1)\n",
        "  avg_recall = 0.0\n",
        "  avg_prec = 0.0\n",
        "  avg_f1 = 0.0\n",
        "  for train, test in skf.split(X, Y):\n",
        "    ab.fit(X[train], Y[train], alter_base = alter_base)\n",
        "    prediction =  ab.predict(X[test])\n",
        "    avg_recall += recall_score(Y[test], prediction)\n",
        "    avg_prec += precision_score(Y[test], prediction)\n",
        "    avg_f1 += f1_score(Y[test], prediction)\n",
        "  \n",
        "  return avg_recall/fold, avg_prec/fold, avg_f1/fold\n",
        "\n",
        "\n",
        "def cross_validation_with_decision_tree(X, y, seed=1, n_estimators=79):\n",
        "  prec_arr = []\n",
        "  rec_arr = []\n",
        "  f1_arr = []\n",
        "  best_k = []\n",
        "  for k in range(190, 300, 1):\n",
        "    under = RandomUnderSampler(random_state=seed)\n",
        "    X_resampled, y_resampled = under.fit_resample(X, y)\n",
        "    fs = SelectKBest(score_func=chi2, k=k)\n",
        "    X_selected = fs.fit_transform(X_resampled, y_resampled)\n",
        "    rec, prec, f1 = stratified_kFold_cross_validation_with_adaboost(X_selected, y_resampled, n_estimators=n_estimators)\n",
        "    best_k.append(k)\n",
        "    prec_arr.append(prec)\n",
        "    rec_arr.append(rec)\n",
        "    f1_arr.append(f1)\n",
        "    print('For %d-Best Feature, Recall-Score: %.3f Precision-Score: %.3f F1-Score: %.3f' % (k, rec, prec, f1))\n",
        "  \n",
        "  plt.plot(best_k, rec_arr, label = \"recall\")\n",
        "  plt.plot(best_k, prec_arr, label = \"precision\")\n",
        "  plt.plot(best_k, f1_arr, label = \"f1-score\")\n",
        "  plt.xlabel('Score')\n",
        "  plt.xlabel('K-best Feature Number')\n",
        "  plt.title('Experiment With AdaBoost (Base = Decision Tree)')\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "def cross_validation_with_decision_tree_n_estimators(X, y, seed=1):\n",
        "  prec_arr = []\n",
        "  rec_arr = []\n",
        "  f1_arr = []\n",
        "  best_n = []\n",
        "  for n in range(3, 50, 1):\n",
        "    under = RandomUnderSampler(random_state=seed)\n",
        "    X_resampled, y_resampled = under.fit_resample(X, y)\n",
        "    fs = SelectKBest(score_func=chi2, k=255)\n",
        "    X_selected = fs.fit_transform(X_resampled, y_resampled)\n",
        "    rec, prec, f1 = stratified_kFold_cross_validation_with_adaboost(X_selected, y_resampled, n_estimators=n)\n",
        "    best_n.append(n)\n",
        "    prec_arr.append(prec)\n",
        "    rec_arr.append(rec)\n",
        "    f1_arr.append(f1)\n",
        "    print('For %d-Number of Estimators, Recall-Score: %.3f Precision-Score: %.3f F1-Score: %.3f' % (n, rec, prec, f1))\n",
        "  \n",
        "  plt.plot(best_n, rec_arr, label = \"recall\")\n",
        "  plt.plot(best_n, prec_arr, label = \"precision\")\n",
        "  plt.plot(best_n, f1_arr, label = \"f1-score\")\n",
        "  plt.xlabel('Score')\n",
        "  plt.xlabel('Number of Estimators')\n",
        "  plt.title('Experiment With AdaBoost (Base = Decision Tree)')\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "def cross_validation_with_bernouli(X, y, seed=1):\n",
        "  prec_arr = []\n",
        "  rec_arr = []\n",
        "  f1_arr = []\n",
        "  best_n = []\n",
        "  for n in range(1, 30, 1):\n",
        "    under = RandomUnderSampler(random_state=seed)\n",
        "    X_resampled, y_resampled = under.fit_resample(X, y)\n",
        "    fs = SelectKBest(score_func=chi2, k=255)\n",
        "    X_selected = fs.fit_transform(X_resampled, y_resampled)\n",
        "    rec, prec, f1 = stratified_kFold_cross_validation_with_adaboost(X_selected, y_resampled, n_estimators=n, alter_base=True)\n",
        "    best_n.append(n)\n",
        "    prec_arr.append(prec)\n",
        "    rec_arr.append(rec)\n",
        "    f1_arr.append(f1)\n",
        "    print('For %d-Number of Estimators, Recall-Score: %.3f Precision-Score: %.3f F1-Score: %.3f' % (n, rec, prec, f1))\n",
        "  \n",
        "  plt.plot(best_n, rec_arr, label = \"recall\")\n",
        "  plt.plot(best_n, prec_arr, label = \"precision\")\n",
        "  plt.plot(best_n, f1_arr, label = \"f1-score\")\n",
        "  plt.xlabel('Score')\n",
        "  plt.xlabel('Number of Estimators')\n",
        "  plt.title('Experiment With AdaBoost (Base = Bernoulli Naive Bayes)')\n",
        "  plt.legend()\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "DHiVG0fGhYfH"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def exp_1():\n",
        "  X = create_sparse_matrix(train_df['attribute'])\n",
        "  Y = train_df['active']\n",
        "  cross_validation_with_decision_tree(X, Y)\n",
        "\n",
        "# exp_1()"
      ],
      "metadata": {
        "id": "lUvJa9PGlB-d"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def exp_2():\n",
        "  X = create_sparse_matrix(train_df['attribute'])\n",
        "  Y = train_df['active']\n",
        "  cross_validation_with_decision_tree_n_estimators(X, Y)\n",
        "\n",
        "# exp_2()"
      ],
      "metadata": {
        "id": "FuIZKSCcugKW"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def exp_3():\n",
        "  X = create_sparse_matrix(train_df['attribute'])\n",
        "  Y = train_df['active']\n",
        "  cross_validation_with_bernouli(X, Y)\n",
        "\n",
        "# exp_3()"
      ],
      "metadata": {
        "id": "-iFow1gUiinv"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Final Prediction on Test Data\n",
        "\n",
        "\n",
        "X = create_sparse_matrix(train_df['attribute'])\n",
        "Y = train_df['active']\n",
        "\n",
        "under =  RandomUnderSampler(random_state=1)\n",
        "X_resampled, y_resampled = under.fit_resample(X, Y)\n",
        "\n",
        "fs = SelectKBest(score_func=chi2, k=255)\n",
        "X_selected = fs.fit_transform(X_resampled, y_resampled)\n",
        "\n",
        "ab = AdaBoostClassifier(n_estimators=14)\n",
        "ab.fit(X_selected, y_resampled, alter_base=True)\n",
        "\n",
        "X_test = create_sparse_matrix(test_df['attribute'])\n",
        "X_test_reduced = fs.transform(X_test)\n",
        "\n",
        "predictions = ab.predict(X_test_reduced)\n",
        "df = pd.DataFrame(predictions)\n",
        "df[0] = df[0].map({1: 1, -1: 0})\n",
        "df.to_csv('final_prediction.csv', index=False, header=False) \n",
        "files.download(\"final_prediction.csv\")"
      ],
      "metadata": {
        "id": "NORIWIGpnBL3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}